[
  {
    "objectID": "slides.html#enabling-analysis-in-the-cloud-using-nasa-earth-science-data",
    "href": "slides.html#enabling-analysis-in-the-cloud-using-nasa-earth-science-data",
    "title": "NASA AGU 2023 Workshop Slides",
    "section": "Enabling Analysis in the Cloud Using NASA Earth Science Data",
    "text": "Enabling Analysis in the Cloud Using NASA Earth Science Data"
  },
  {
    "objectID": "qtutorials/earthdataaccess.html",
    "href": "qtutorials/earthdataaccess.html",
    "title": "Intro to earthdataaccess",
    "section": "",
    "text": "This is the “Data Cubes with STAC” vignette from earthdataaccess package.\nHigh-resolution satellites generate many snapshot images each with a limited field of view or spatial extent. In order to see a larger area in space, and/or observe changes across space and time, we need to assemble these many snapshots into a mosaic or “data cube” that we can analyze as a cohesive whole.\nEARTHDATA STAC CATALOGS"
  },
  {
    "objectID": "qtutorials/earthdataaccess.html#install-earthdatalogin",
    "href": "qtutorials/earthdataaccess.html#install-earthdatalogin",
    "title": "Intro to earthdataaccess",
    "section": "Install earthdatalogin",
    "text": "Install earthdatalogin\nInstall earthdatalogin and update terra\n\ninstall.packages(\"earthdatalogin\")\ninstall.packages(\"terra\")"
  },
  {
    "objectID": "qtutorials/earthdataaccess.html#basic-use",
    "href": "qtutorials/earthdataaccess.html#basic-use",
    "title": "Intro to earthdataaccess",
    "section": "Basic Use",
    "text": "Basic Use\nFirst let’s get NASA Earth Data Login (EDL) authentication out of the way. For cloud data from almost any other STAC catalog (NOAA, USGS, Planetary Computer, etc), authentication is either unnecessary or already provided by the STAC API, but NASA EDL is special.\n\nlibrary(earthdatalogin)\n# Authenticate\nedl_netrc()\n\nGet data.\n\nlibrary(terra)\n\nterra 1.7.65\n\nurl &lt;- \"https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/HLSL30.020/HLS.L30.T56JKT.2023246T235950.v2.0/HLS.L30.T56JKT.2023246T235950.v2.0.SAA.tif\"\nras &lt;- terra::rast(url, vsi=TRUE)\n\nThis is a boring and weird example. The plot is correct.\n\nplot(ras)"
  },
  {
    "objectID": "qtutorials/earthdataaccess.html#searching-and-subsetting",
    "href": "qtutorials/earthdataaccess.html#searching-and-subsetting",
    "title": "Intro to earthdataaccess",
    "section": "Searching and Subsetting",
    "text": "Searching and Subsetting\nThe packages we want\n\nlibrary(rstac)\nlibrary(gdalcubes)\n\n\nAttaching package: 'gdalcubes'\n\n\nThe following objects are masked from 'package:terra':\n\n    animate, crop, size\n\ngdalcubes_options(parallel = TRUE) \n\n\nEDL Authentication\nAs usual, we can handle this with edl_netrc(). Because the gdalcubes package doesn’t respect global environmental variables, we use a helper utility to export those into its configuration as well.\n\nlibrary(earthdatalogin)\nedl_netrc()\nwith_gdalcubes()\n\n\n\nSearch via STAC\nWe will now use the rstac package to search one or more NASA collections for data that falls into our desired bounding box of space and time. NASA has a CMR option for searching that is more stable but this example is using STAC which is a more universal option.\n\nbbox &lt;- c(xmin=-123, ymin=37.25, xmax=-122.0, ymax=38.25) \nstart &lt;- \"2021-12-01\"\nend &lt;- \"2022-01-31\"\n\n# Find all assets from the desired catalog:\nitems &lt;- stac(\"https://cmr.earthdata.nasa.gov/stac/LPCLOUD\") |&gt; \n  stac_search(collections = \"HLSL30.v2.0\",\n              bbox = bbox,\n              datetime = paste(start,end, sep = \"/\")) |&gt;\n  post_request() |&gt;\n  items_fetch() |&gt;\n  items_filter(filter_fn = \\(x) {x[[\"eo:cloud_cover\"]] &lt; 20})\n\n\n  |                                                                            \n  |======================================================================| 100%\n\n\nWarning: In version 0.9.2, rstac changed how filter function is evaluated. In future versions, the `filter_fn` parameter will be evaluated against each feature in items instead of `properties` field.\nSee ?items_filter for more details on how to change your function.\n\n\nNote that 98 features have matched our search criteria! Each feature represents a ‘snapshot’ image taken by the satellite as it passes by (this is a harmonized product so actually there’s quite a lot of post-processing.) Each feature thus shares the same bounding box, projection, and timestamp, but may consist of many different ‘assets’, different files representing the different spectral bands on the satellite camera instrument. Each feature can potentially include quite extensive metadata about the feature, including details of instrument itself or from post-processing, such as cloud cover. Unfortunately, Earth Data’s STAC metadata tends to be quite sparse.\n\n\nBuilding a Data Cube\n\n# Desired data cube shape & resolution\nv = cube_view(srs = \"EPSG:4326\",\n              extent = list(t0 = as.character(start), \n                            t1 = as.character(end),\n                            left = bbox[1], right = bbox[3],\n                            top = bbox[4], bottom = bbox[2]),\n              nx = 512, ny = 512, dt = \"P1M\")\n\nRGB bands + cloud cover mask\n\ncol &lt;- stac_image_collection(items$features, \n                             asset_names = c(\"B02\", \"B03\", \"B04\", \"Fmask\"))\n\nWarning in stac_image_collection(items$features, asset_names = c(\"B02\", : STAC\nasset with name 'B02' does not include eo:bands metadata and will be considered\nas a single band source\n\n\nWarning in stac_image_collection(items$features, asset_names = c(\"B02\", : STAC\nasset with name 'B03' does not include eo:bands metadata and will be considered\nas a single band source\n\n\nWarning in stac_image_collection(items$features, asset_names = c(\"B02\", : STAC\nasset with name 'B04' does not include eo:bands metadata and will be considered\nas a single band source\n\n\nWarning in stac_image_collection(items$features, asset_names = c(\"B02\", : STAC\nasset with name 'Fmask' does not include eo:bands metadata and will be\nconsidered as a single band source\n\n\nUse a cloud mask. See HLS User Guide.\n\ncloud_mask &lt;- image_mask(\"Fmask\", values=1)\n\n\n\nPlot\nThis takes awhile. So far we have not downloaded anything. We have been working with metadata about the files. Now we do the work which involves server-side subsetting and some operations. We download on the part that we need.\n\nraster_cube(col, v, mask=cloud_mask) |&gt;\n  select_bands(c(\"B02\",\"B03\", \"B04\")) |&gt;\n  plot(rgb=3:1)"
  },
  {
    "objectID": "prerequisites.html#before-the-workshop-you-will-need-the-following",
    "href": "prerequisites.html#before-the-workshop-you-will-need-the-following",
    "title": "Prerequisites",
    "section": "Before the Workshop, you will need the following:",
    "text": "Before the Workshop, you will need the following:\n\n1. Earthdata Login Account\nAn Earthdata Login account is required to access data, as well as discover restricted data, from the NASA Earthdata system. Thus, to access NASA data, you need Earthdata Login. Please visit https://urs.earthdata.nasa.gov to register and manage your Earthdata Login account. This account is free to create and only takes a moment to set up. Please remember your username and password!\n\n\n2. GitHub Account\nA GitHub account is required to gain access to the JupyterHub.\n\n\n3. Laptop or tablet\nParticipation in the exercises requires a laptop or tablet. Yes, a tablet works too!"
  },
  {
    "objectID": "itutorials/Earthdata_Subset_and_Plot.html#summary",
    "href": "itutorials/Earthdata_Subset_and_Plot.html#summary",
    "title": "Data subsetting and plotting with earthaccess and xarray",
    "section": "Summary",
    "text": "Summary\nIn this examples we will use the xarray and earthaccess to subset data and make figures."
  },
  {
    "objectID": "itutorials/Earthdata_Subset_and_Plot.html#learning-objectives",
    "href": "itutorials/Earthdata_Subset_and_Plot.html#learning-objectives",
    "title": "Data subsetting and plotting with earthaccess and xarray",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nExtract variables, temporal slices, and spatial slices from an xarray dataset\nPlot data and exclude data points via boolean conditions, using xarray, cartopy, and matplotlib\n\n\nImport Required Packages\n\n# Suppress warnings\nimport warnings\nwarnings.simplefilter('ignore')\nwarnings.filterwarnings('ignore')\nfrom pprint import pprint\n\nimport earthaccess\nimport xarray as xr\nxr.set_options(display_expand_attrs=False)\nimport matplotlib.pyplot as plt\nimport cartopy.crs as ccrs\nimport cartopy.feature as cfeature\n\n%matplotlib inline"
  },
  {
    "objectID": "itutorials/Earthdata_Subset_and_Plot.html#authenticate-to-nasa-earthdata",
    "href": "itutorials/Earthdata_Subset_and_Plot.html#authenticate-to-nasa-earthdata",
    "title": "Data subsetting and plotting with earthaccess and xarray",
    "section": "Authenticate to NASA Earthdata",
    "text": "Authenticate to NASA Earthdata\nWe will authenticate our Earthaccess session, and then open the results like we did in the Search & Discovery section.\n\n# Bug on dhub settings is setting the home to /home/rstudio\nimport os\nos.environ[\"HOME\"] = \"/home/jovyan\"\n\n\nauth = earthaccess.login()\n# are we authenticated?\nif not auth.authenticated:\n    # ask for credentials and persist them in a .netrc file\n    auth.login(strategy=\"interactive\", persist=True)\n\nEDL_USERNAME and EDL_PASSWORD are not set in the current environment, try setting them or use a different strategy (netrc, interactive)\nYou're now authenticated with NASA Earthdata Login\nUsing token with expiration date: 01/29/2024\nUsing .netrc file for EDL"
  },
  {
    "objectID": "itutorials/Earthdata_Subset_and_Plot.html#xarray-subsetting---precipitation-estimates-from-imerg-daily-level-3",
    "href": "itutorials/Earthdata_Subset_and_Plot.html#xarray-subsetting---precipitation-estimates-from-imerg-daily-level-3",
    "title": "Data subsetting and plotting with earthaccess and xarray",
    "section": "Xarray Subsetting - Precipitation estimates from IMERG, Daily Level 3",
    "text": "Xarray Subsetting - Precipitation estimates from IMERG, Daily Level 3\n\nDataset\nWe will use the GPM IMERG Final Precipitation L3 Daily dataset for this tutorial. The IMERG Precipitation Rate provides the rain and snow rates in millimeters per hour (mm/hr). It is estimated by the Integrated Multi-satellitE Retrievals for Global Precipitation Measurement (GPM) (IMERG) algorithm. The IMERG algorithm uses passive-microwave data from the GPM constellation of satellites and infrared data from geosynchronous satellites. IMERG “morphs” observations to earlier or later times using wind from weather-model analyses. The daily IMERG dataset is derived from the half-hourly GPM_3IMERGHH. The derived result represents the final estimate of the daily mean precipitation rate in mm/day.\nLink to data on NASA Earthdata\nThe IMERG data has 0.1 x 0.1 degree latitude-longitude resolution (approximately 11 by 11 km at the Equator). The grid covers the globe, although precipitation cannot always be estimated near the Poles. The dataset and algorithm are described in the data user guide and the Algorithm Theoretical Basis Document (ATBD).\nPlease cite the dataset as: &gt; Huffman, G.J., E.F. Stocker, D.T. Bolvin, E.J. Nelkin, Jackson Tan (2023), GPM IMERG Final Precipitation L3 1 day 0.1 degree x 0.1 degree V07, Edited by Andrey Savtchenko, Greenbelt, MD, Goddard Earth Sciences Data and Information Services Center (GES DISC), https://doi.org/10.5067/GPM/IMERGDF/DAY/07\n\ncollection_id = 'C2723754864-GES_DISC'  # GPM IMERG Final Precipitation L3 1 day 0.1 degree x 0.1 degree V07 (GPM_3IMERGDF)\n# Seems to be a bug in the collection above so I am using older data\n\n# Bounds within which we search for data granules\ndate_start = \"2015-02-25\"\ndate_end = \"2015-02-26\"\ndate_range = (date_start, date_end)\nbbox = (-127.0761, 31.6444, -113.9039, 42.6310)  # min lon, min lat, max lon, max lat\n\n# For reference (e.g., to visualize in https://geojson.io/), here is a GeoJSON representing the above bounding box:\n# {\"type\": \"FeatureCollection\", \"features\": [{\"type\": \"Feature\", \"properties\": {}, \"geometry\": {\"type\": \"LineString\", \"bbox\": [-127.0761, 31.6444, -113.9039, 42.631], \"coordinates\": [[-113.9039, 42.631], [-127.0761,42.631], [-127.0761, 31.6444], [-113.9039, 31.6444], [-113.9039, 42.631]]}}]}\n\nresults = earthaccess.search_data(\n    concept_id = collection_id,\n    cloud_hosted = True,\n    temporal = date_range,\n    bounding_box = bbox,\n)\n\nGranules found: 2\n\n\n\nds = xr.open_mfdataset(earthaccess.open(results))\n\n Opening 2 granules, approx size: 0.05 GB\n\n\n\n\n\n\n\n\n\n\n\nNote that xarray works with “lazy” computation whenever possible. In this case, the metadata are loaded into JupyterHub memory, but the data arrays and their values are not — until there is a need for them.\nLet’s print out all the variable names.\n\nfor v in ds.variables:\n    print(v)\n\nprecipitation\nprecipitation_cnt\nprecipitation_cnt_cond\nMWprecipitation\nMWprecipitation_cnt\nMWprecipitation_cnt_cond\nrandomError\nrandomError_cnt\nprobabilityLiquidPrecipitation\nlon\nlat\ntime\ntime_bnds\n\n\nOf the variables listed above, we are interested in three variables: precipitation, precipitation_cnt_cond, and probabilityLiquidPrecipitation. Let’s print their attributes.\n\nds.variables['precipitation'].attrs\n\n{'units': 'mm/day',\n 'long_name': 'Daily mean precipitation rate (combined microwave-IR) estimate. Formerly precipitationCal.'}\n\n\n\nds.variables['precipitation_cnt_cond'].attrs\n\n{'units': 'count',\n 'long_name': 'Count of half-hourly precipitation retrievals for the day where precipitation is at least 0.01 mm/hr'}\n\n\n\nds.variables['probabilityLiquidPrecipitation'].attrs\n\n{'units': 'percent',\n 'long_name': 'Probability of liquid precipitation',\n 'description': 'Probability of liquid precipitation estimated with a diagnostic parameterization using ancillary data. 0=missing values; 1=likely solid; 100=likely liquid or no precipitation.  Screen by positive precipitation or precipitation_cnt_cond to locate meaningful probabilities.'}\n\n\n\n\nSubsetting\nIn addition to directly accessing the files archived and distributed by each of the NASA DAACs, many datasets also support services that allow us to customize the data via subsetting, reformatting, reprojection/regridding, and file aggregation. What does subsetting mean? To subset means to extract only the portions of a dataset that are needed for a given purpose.\nThere are three primary types of subsetting that we will walk through: 1. Temporal 2. Spatial 3. Variable\nIn each case, we will be excluding parts of the dataset that are not wanted using xarray. Note that “subsetting” is also called a data “transformation”.\n\nds.time.values\n\narray(['2015-02-25T00:00:00.000000000', '2015-02-26T00:00:00.000000000'],\n      dtype='datetime64[ns]')\n\n\nWe start with a subset that represents the U.S. state of California. Notice the dimensions of the Dataset and each variable — time, lon, lat, and ‘nv’ (number of vertices) for the bounds variable.\n\n# Display the full dataset's metadata\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:                         (time: 2, lon: 3600, lat: 1800, nv: 2)\nCoordinates:\n  * lon                             (lon) float32 -179.9 -179.9 ... 179.9 179.9\n  * lat                             (lat) float64 -89.95 -89.85 ... 89.85 89.95\n  * time                            (time) datetime64[ns] 2015-02-25 2015-02-26\nDimensions without coordinates: nv\nData variables:\n    precipitation                   (time, lon, lat) float32 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    precipitation_cnt               (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    precipitation_cnt_cond          (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    MWprecipitation                 (time, lon, lat) float32 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    MWprecipitation_cnt             (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    MWprecipitation_cnt_cond        (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    randomError                     (time, lon, lat) float32 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    randomError_cnt                 (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    probabilityLiquidPrecipitation  (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    time_bnds                       (time, nv) datetime64[ns] dask.array&lt;chunksize=(1, 2), meta=np.ndarray&gt;\nAttributes: (9)xarray.DatasetDimensions:time: 2lon: 3600lat: 1800nv: 2Coordinates: (3)lon(lon)float32-179.9 -179.9 ... 179.9 179.9units :degrees_eastlong_name :Longitudearray([-179.95, -179.85, -179.75, ...,  179.75,  179.85,  179.95],\n      dtype=float32)lat(lat)float64-89.95 -89.85 ... 89.85 89.95units :degrees_northlong_name :Latitudearray([-89.95, -89.85, -89.75, ...,  89.75,  89.85,  89.95])time(time)datetime64[ns]2015-02-25 2015-02-26standard_name :timelong_name :timebounds :time_bndsarray(['2015-02-25T00:00:00.000000000', '2015-02-26T00:00:00.000000000'],\n      dtype='datetime64[ns]')Data variables: (10)precipitation(time, lon, lat)float32dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;units :mm/daylong_name :Daily mean precipitation rate (combined microwave-IR) estimate. Formerly precipitationCal.\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n49.44 MiB\n24.72 MiB\n\n\nShape\n(2, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n2 chunks in 5 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\nprecipitation_cnt\n\n\n(time, lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\ncount\n\nlong_name :\n\nCount of all valid half-hourly precipitation retrievals for the day\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n12.36 MiB\n6.18 MiB\n\n\nShape\n(2, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n2 chunks in 5 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n\n\n\n\n\nprecipitation_cnt_cond\n\n\n(time, lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\ncount\n\nlong_name :\n\nCount of half-hourly precipitation retrievals for the day where precipitation is at least 0.01 mm/hr\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n12.36 MiB\n6.18 MiB\n\n\nShape\n(2, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n2 chunks in 5 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n\n\n\n\n\nMWprecipitation\n\n\n(time, lon, lat)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\nmm/day\n\nlong_name :\n\nDaily mean High Quality precipitation rate from all available microwave sources. Formerly HQprecipitation.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n49.44 MiB\n24.72 MiB\n\n\nShape\n(2, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n2 chunks in 5 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\n\nMWprecipitation_cnt\n\n\n(time, lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\ncount\n\nlong_name :\n\nCount of all valid half-hourly MWprecipitation retrievals for the day\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n12.36 MiB\n6.18 MiB\n\n\nShape\n(2, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n2 chunks in 5 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n\n\n\n\n\nMWprecipitation_cnt_cond\n\n\n(time, lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\ncount\n\nlong_name :\n\nCount of half-hourly MWprecipitation retrievals for the day where precipitation is at least 0.01 mm/hr\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n12.36 MiB\n6.18 MiB\n\n\nShape\n(2, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n2 chunks in 5 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n\n\n\n\n\nrandomError\n\n\n(time, lon, lat)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\nmm/day\n\nlong_name :\n\nRoot-mean-square error estimate for combined microwave-IR daily precipitation rate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n49.44 MiB\n24.72 MiB\n\n\nShape\n(2, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n2 chunks in 5 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\n\nrandomError_cnt\n\n\n(time, lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\ncount\n\nlong_name :\n\nCount of valid half-hourly randomError retrievals for the day\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n12.36 MiB\n6.18 MiB\n\n\nShape\n(2, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n2 chunks in 5 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n\n\n\n\n\nprobabilityLiquidPrecipitation\n\n\n(time, lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\npercent\n\nlong_name :\n\nProbability of liquid precipitation\n\ndescription :\n\nProbability of liquid precipitation estimated with a diagnostic parameterization using ancillary data. 0=missing values; 1=likely solid; 100=likely liquid or no precipitation. Screen by positive precipitation or precipitation_cnt_cond to locate meaningful probabilities.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n12.36 MiB\n6.18 MiB\n\n\nShape\n(2, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n2 chunks in 5 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n\n\n\n\n\ntime_bnds\n\n\n(time, nv)\n\n\ndatetime64[ns]\n\n\ndask.array&lt;chunksize=(1, 2), meta=np.ndarray&gt;\n\n\n\n\ncoordinates :\n\ntime nv\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n32 B\n16 B\n\n\nShape\n(2, 2)\n(1, 2)\n\n\nDask graph\n2 chunks in 5 graph layers\n\n\nData type\ndatetime64[ns] numpy.ndarray\n\n\n\n\n\n\n\n\nIndexes: (3)lonPandasIndexPandasIndex(Float64Index([ -179.9499969482422, -179.85000610351562,             -179.75,\n              -179.64999389648438,  -179.5500030517578,  -179.4499969482422,\n              -179.35000610351562,             -179.25, -179.14999389648438,\n               -179.0500030517578,\n              ...\n                179.0500030517578,  179.14999389648438,              179.25,\n               179.35000610351562,   179.4499969482422,   179.5500030517578,\n               179.64999389648438,              179.75,  179.85000610351562,\n                179.9499969482422],\n             dtype='float64', name='lon', length=3600))latPandasIndexPandasIndex(Float64Index([            -89.95, -89.85000000000001,             -89.75,\n                          -89.65,             -89.55,             -89.45,\n              -89.35000000000001,             -89.25,             -89.15,\n                          -89.05,\n              ...\n                           89.05,  89.15000000000002,  89.25000000000001,\n               89.35000000000001,              89.45,              89.55,\n               89.65000000000002,  89.75000000000001,  89.85000000000001,\n                           89.95],\n             dtype='float64', name='lat', length=1800))timePandasIndexPandasIndex(DatetimeIndex(['2015-02-25', '2015-02-26'], dtype='datetime64[ns]', name='time', freq=None))Attributes: (9)BeginDate :2015-02-25BeginTime :00:00:00.000ZEndDate :2015-02-25EndTime :23:59:59.999ZFileHeader :StartGranuleDateTime=2015-02-25T00:00:00.000Z;\nStopGranuleDateTime=2015-02-25T23:59:59.999ZInputPointer :3B-HHR.MS.MRG.3IMERG.20150225-S000000-E002959.0000.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S003000-E005959.0030.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S010000-E012959.0060.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S013000-E015959.0090.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S020000-E022959.0120.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S023000-E025959.0150.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S030000-E032959.0180.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S033000-E035959.0210.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S040000-E042959.0240.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S043000-E045959.0270.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S050000-E052959.0300.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S053000-E055959.0330.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S060000-E062959.0360.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S063000-E065959.0390.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S070000-E072959.0420.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S073000-E075959.0450.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S080000-E082959.0480.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S083000-E085959.0510.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S090000-E092959.0540.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S093000-E095959.0570.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S100000-E102959.0600.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S103000-E105959.0630.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S110000-E112959.0660.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S113000-E115959.0690.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S120000-E122959.0720.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S123000-E125959.0750.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S130000-E132959.0780.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S133000-E135959.0810.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S140000-E142959.0840.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S143000-E145959.0870.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S150000-E152959.0900.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S153000-E155959.0930.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S160000-E162959.0960.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S163000-E165959.0990.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S170000-E172959.1020.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S173000-E175959.1050.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S180000-E182959.1080.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S183000-E185959.1110.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S190000-E192959.1140.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S193000-E195959.1170.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S200000-E202959.1200.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S203000-E205959.1230.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S210000-E212959.1260.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S213000-E215959.1290.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S220000-E222959.1320.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S223000-E225959.1350.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S230000-E232959.1380.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S233000-E235959.1410.V07B.HDF5title :GPM IMERG Final Precipitation L3 1 day 0.1 degree x 0.1 degree (GPM_3IMERGDF)DOI :10.5067/GPM/IMERGDF/DAY/07ProductionTime :2023-12-18T14:54:02.047Z\n\n\nNow we will prepare a subset. We’re using essentially the same spatial bounds as above; however, as opposed to the earthaccess inputs above, here we must provide inputs in the formats expected by xarray. Instead of a single, four-element, bounding box, we use Python slice objects, which are defined by starting and ending numbers.\n\nds_subset = ds.sel(time=date_start, lat=slice(31, 43), lon=slice(-125, -113)) \nds_subset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:                         (lon: 120, lat: 120, nv: 2)\nCoordinates:\n  * lon                             (lon) float32 -124.9 -124.8 ... -113.1\n  * lat                             (lat) float64 31.05 31.15 ... 42.85 42.95\n    time                            datetime64[ns] 2015-02-25\nDimensions without coordinates: nv\nData variables:\n    precipitation                   (lon, lat) float32 dask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n    precipitation_cnt               (lon, lat) int8 dask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n    precipitation_cnt_cond          (lon, lat) int8 dask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n    MWprecipitation                 (lon, lat) float32 dask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n    MWprecipitation_cnt             (lon, lat) int8 dask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n    MWprecipitation_cnt_cond        (lon, lat) int8 dask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n    randomError                     (lon, lat) float32 dask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n    randomError_cnt                 (lon, lat) int8 dask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n    probabilityLiquidPrecipitation  (lon, lat) int8 dask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n    time_bnds                       (nv) datetime64[ns] dask.array&lt;chunksize=(2,), meta=np.ndarray&gt;\nAttributes: (9)xarray.DatasetDimensions:lon: 120lat: 120nv: 2Coordinates: (3)lon(lon)float32-124.9 -124.8 ... -113.2 -113.1units :degrees_eastlong_name :Longitudearray([-124.95, -124.85, -124.75, -124.65, -124.55, -124.45, -124.35, -124.25,\n       -124.15, -124.05, -123.95, -123.85, -123.75, -123.65, -123.55, -123.45,\n       -123.35, -123.25, -123.15, -123.05, -122.95, -122.85, -122.75, -122.65,\n       -122.55, -122.45, -122.35, -122.25, -122.15, -122.05, -121.95, -121.85,\n       -121.75, -121.65, -121.55, -121.45, -121.35, -121.25, -121.15, -121.05,\n       -120.95, -120.85, -120.75, -120.65, -120.55, -120.45, -120.35, -120.25,\n       -120.15, -120.05, -119.95, -119.85, -119.75, -119.65, -119.55, -119.45,\n       -119.35, -119.25, -119.15, -119.05, -118.95, -118.85, -118.75, -118.65,\n       -118.55, -118.45, -118.35, -118.25, -118.15, -118.05, -117.95, -117.85,\n       -117.75, -117.65, -117.55, -117.45, -117.35, -117.25, -117.15, -117.05,\n       -116.95, -116.85, -116.75, -116.65, -116.55, -116.45, -116.35, -116.25,\n       -116.15, -116.05, -115.95, -115.85, -115.75, -115.65, -115.55, -115.45,\n       -115.35, -115.25, -115.15, -115.05, -114.95, -114.85, -114.75, -114.65,\n       -114.55, -114.45, -114.35, -114.25, -114.15, -114.05, -113.95, -113.85,\n       -113.75, -113.65, -113.55, -113.45, -113.35, -113.25, -113.15, -113.05],\n      dtype=float32)lat(lat)float6431.05 31.15 31.25 ... 42.85 42.95units :degrees_northlong_name :Latitudearray([31.05, 31.15, 31.25, 31.35, 31.45, 31.55, 31.65, 31.75, 31.85, 31.95,\n       32.05, 32.15, 32.25, 32.35, 32.45, 32.55, 32.65, 32.75, 32.85, 32.95,\n       33.05, 33.15, 33.25, 33.35, 33.45, 33.55, 33.65, 33.75, 33.85, 33.95,\n       34.05, 34.15, 34.25, 34.35, 34.45, 34.55, 34.65, 34.75, 34.85, 34.95,\n       35.05, 35.15, 35.25, 35.35, 35.45, 35.55, 35.65, 35.75, 35.85, 35.95,\n       36.05, 36.15, 36.25, 36.35, 36.45, 36.55, 36.65, 36.75, 36.85, 36.95,\n       37.05, 37.15, 37.25, 37.35, 37.45, 37.55, 37.65, 37.75, 37.85, 37.95,\n       38.05, 38.15, 38.25, 38.35, 38.45, 38.55, 38.65, 38.75, 38.85, 38.95,\n       39.05, 39.15, 39.25, 39.35, 39.45, 39.55, 39.65, 39.75, 39.85, 39.95,\n       40.05, 40.15, 40.25, 40.35, 40.45, 40.55, 40.65, 40.75, 40.85, 40.95,\n       41.05, 41.15, 41.25, 41.35, 41.45, 41.55, 41.65, 41.75, 41.85, 41.95,\n       42.05, 42.15, 42.25, 42.35, 42.45, 42.55, 42.65, 42.75, 42.85, 42.95])time()datetime64[ns]2015-02-25standard_name :timelong_name :timebounds :time_bndsarray('2015-02-25T00:00:00.000000000', dtype='datetime64[ns]')Data variables: (10)precipitation(lon, lat)float32dask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;units :mm/daylong_name :Daily mean precipitation rate (combined microwave-IR) estimate. Formerly precipitationCal.\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n56.25 kiB\n56.25 kiB\n\n\nShape\n(120, 120)\n(120, 120)\n\n\nDask graph\n1 chunks in 6 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\nprecipitation_cnt\n\n\n(lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\ncount\n\nlong_name :\n\nCount of all valid half-hourly precipitation retrievals for the day\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n14.06 kiB\n14.06 kiB\n\n\nShape\n(120, 120)\n(120, 120)\n\n\nDask graph\n1 chunks in 6 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n\n\n\n\n\nprecipitation_cnt_cond\n\n\n(lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\ncount\n\nlong_name :\n\nCount of half-hourly precipitation retrievals for the day where precipitation is at least 0.01 mm/hr\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n14.06 kiB\n14.06 kiB\n\n\nShape\n(120, 120)\n(120, 120)\n\n\nDask graph\n1 chunks in 6 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n\n\n\n\n\nMWprecipitation\n\n\n(lon, lat)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\nmm/day\n\nlong_name :\n\nDaily mean High Quality precipitation rate from all available microwave sources. Formerly HQprecipitation.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n56.25 kiB\n56.25 kiB\n\n\nShape\n(120, 120)\n(120, 120)\n\n\nDask graph\n1 chunks in 6 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\n\nMWprecipitation_cnt\n\n\n(lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\ncount\n\nlong_name :\n\nCount of all valid half-hourly MWprecipitation retrievals for the day\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n14.06 kiB\n14.06 kiB\n\n\nShape\n(120, 120)\n(120, 120)\n\n\nDask graph\n1 chunks in 6 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n\n\n\n\n\nMWprecipitation_cnt_cond\n\n\n(lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\ncount\n\nlong_name :\n\nCount of half-hourly MWprecipitation retrievals for the day where precipitation is at least 0.01 mm/hr\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n14.06 kiB\n14.06 kiB\n\n\nShape\n(120, 120)\n(120, 120)\n\n\nDask graph\n1 chunks in 6 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n\n\n\n\n\nrandomError\n\n\n(lon, lat)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\nmm/day\n\nlong_name :\n\nRoot-mean-square error estimate for combined microwave-IR daily precipitation rate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n56.25 kiB\n56.25 kiB\n\n\nShape\n(120, 120)\n(120, 120)\n\n\nDask graph\n1 chunks in 6 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\n\nrandomError_cnt\n\n\n(lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\ncount\n\nlong_name :\n\nCount of valid half-hourly randomError retrievals for the day\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n14.06 kiB\n14.06 kiB\n\n\nShape\n(120, 120)\n(120, 120)\n\n\nDask graph\n1 chunks in 6 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n\n\n\n\n\nprobabilityLiquidPrecipitation\n\n\n(lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\npercent\n\nlong_name :\n\nProbability of liquid precipitation\n\ndescription :\n\nProbability of liquid precipitation estimated with a diagnostic parameterization using ancillary data. 0=missing values; 1=likely solid; 100=likely liquid or no precipitation. Screen by positive precipitation or precipitation_cnt_cond to locate meaningful probabilities.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n14.06 kiB\n14.06 kiB\n\n\nShape\n(120, 120)\n(120, 120)\n\n\nDask graph\n1 chunks in 6 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n\n\n\n\n\ntime_bnds\n\n\n(nv)\n\n\ndatetime64[ns]\n\n\ndask.array&lt;chunksize=(2,), meta=np.ndarray&gt;\n\n\n\n\ncoordinates :\n\ntime nv\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n16 B\n16 B\n\n\nShape\n(2,)\n(2,)\n\n\nDask graph\n1 chunks in 6 graph layers\n\n\nData type\ndatetime64[ns] numpy.ndarray\n\n\n\n\n\n\n\n\nIndexes: (2)lonPandasIndexPandasIndex(Float64Index([-124.94999694824219,  -124.8499984741211,             -124.75,\n               -124.6500015258789, -124.55000305175781, -124.44999694824219,\n               -124.3499984741211,             -124.25,  -124.1500015258789,\n              -124.05000305175781,\n              ...\n              -113.94999694824219,  -113.8499984741211,             -113.75,\n               -113.6500015258789, -113.55000305175781, -113.44999694824219,\n               -113.3499984741211,             -113.25,  -113.1500015258789,\n              -113.05000305175781],\n             dtype='float64', name='lon', length=120))latPandasIndexPandasIndex(Float64Index([             31.05,  31.15000000000001, 31.250000000000004,\n              31.350000000000012, 31.450000000000006,              31.55,\n               31.65000000000001, 31.750000000000004, 31.850000000000012,\n              31.950000000000006,\n              ...\n                           42.05,  42.14999999999999, 42.250000000000014,\n               42.35000000000001,              42.45,              42.55,\n               42.64999999999999, 42.750000000000014,  42.85000000000001,\n                           42.95],\n             dtype='float64', name='lat', length=120))Attributes: (9)BeginDate :2015-02-25BeginTime :00:00:00.000ZEndDate :2015-02-25EndTime :23:59:59.999ZFileHeader :StartGranuleDateTime=2015-02-25T00:00:00.000Z;\nStopGranuleDateTime=2015-02-25T23:59:59.999ZInputPointer :3B-HHR.MS.MRG.3IMERG.20150225-S000000-E002959.0000.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S003000-E005959.0030.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S010000-E012959.0060.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S013000-E015959.0090.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S020000-E022959.0120.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S023000-E025959.0150.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S030000-E032959.0180.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S033000-E035959.0210.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S040000-E042959.0240.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S043000-E045959.0270.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S050000-E052959.0300.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S053000-E055959.0330.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S060000-E062959.0360.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S063000-E065959.0390.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S070000-E072959.0420.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S073000-E075959.0450.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S080000-E082959.0480.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S083000-E085959.0510.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S090000-E092959.0540.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S093000-E095959.0570.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S100000-E102959.0600.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S103000-E105959.0630.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S110000-E112959.0660.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S113000-E115959.0690.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S120000-E122959.0720.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S123000-E125959.0750.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S130000-E132959.0780.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S133000-E135959.0810.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S140000-E142959.0840.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S143000-E145959.0870.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S150000-E152959.0900.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S153000-E155959.0930.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S160000-E162959.0960.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S163000-E165959.0990.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S170000-E172959.1020.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S173000-E175959.1050.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S180000-E182959.1080.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S183000-E185959.1110.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S190000-E192959.1140.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S193000-E195959.1170.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S200000-E202959.1200.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S203000-E205959.1230.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S210000-E212959.1260.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S213000-E215959.1290.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S220000-E222959.1320.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S223000-E225959.1350.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S230000-E232959.1380.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S233000-E235959.1410.V07B.HDF5title :GPM IMERG Final Precipitation L3 1 day 0.1 degree x 0.1 degree (GPM_3IMERGDF)DOI :10.5067/GPM/IMERGDF/DAY/07ProductionTime :2023-12-18T14:54:02.047Z\n\n\nNotice the differences?\n\n\nPlotting\nWe will first plot using the methods built-in to the xarray package.\nNote that, as opposed to the “lazy” loading of metadata previously, this will now perform “eager” computation, pulling the required data chunks.\n\nds_subset['precipitation'].plot(figsize=(10,6), x='lon', y='lat');\n\n\n\n\nNow let’s utilize the “Probability of liquid precipitation phase” (probabilityLiquidPrecipitation) variable to split apart the snow precipitation from everything else. From the variable’s description attribute, we can see that “0=missing values; 1=likely solid; 100=likely liquid or no precipitation”.\nMoreover, we’ll utilize precipitation_cnt_cond to filter out data points that had less than 0.01 mm/hr preciptation amounts.\n\nsnow = ds_subset['precipitation'].where(\n    (ds_subset.precipitation_cnt_cond&gt;0) & (ds_subset.probabilityLiquidPrecipitation == 1)\n)\n\nprcp = ds_subset['precipitation'].where(\n    (ds_subset.precipitation_cnt_cond&gt;0) & (ds_subset.probabilityLiquidPrecipitation != 1)\n)\n\nIn the following plotting commands, we utilize cartopy and matplotlib to generate a more customized figure.\ncartopy is used to set the map projection (to PlateCarree) and to add U.S. state boundary lines to the figure. matplotlib’s pcolormesh is used to generate the color plot, with colors determined by the third argument’s value.\n\n# create the plot\nproj = ccrs.PlateCarree()\nfig, ax = plt.subplots(figsize=(8,5), dpi=130, facecolor=\"w\", subplot_kw=dict(projection=proj))\n\nsnowax = plt.pcolormesh(prcp.lon, prcp.lat, snow.squeeze(), vmax=53, cmap='cool')\nprcpax = plt.pcolormesh(prcp.lon, prcp.lat, prcp.squeeze(), vmax=53, cmap='RdYlGn')\n\nplt.colorbar(snowax, ax=ax, label=\"snow (mm/day)\")\nplt.colorbar(prcpax, ax=ax, label=\"rainfall (mm/day)\")\nax.add_feature(cfeature.STATES)\nax.set_extent([-125, -113.0, 31.0, 43.0], crs=proj)\nax.set_title(f'Precipitation {date_start}')\n\nplt.show()\n\n\n\n\nNotice the enhancements?\nAlso, note that you can explore these (and other) data before generating your own customized plots, by using NASA Worldview. Here’s a link to an example map on Worldview for these IMERG data.\nEND of Notebook."
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Using Earth Data in R and Python",
    "section": "Welcome",
    "text": "Welcome\nUse this form to sign-up to be alerted for future hackdays and Intro to JupyterHubs sessions: SIGN-UP FORM\nContact or questions: Eli Holmes (NOAA) - Type my name in your NOAA email, and my contact will pop up. Note, it uses “Eli” not “Elizabeth”.\n\nFriday Hackhours in March 2024 12-1pm PT/3-4pm ET\nDuring these 1 hour hackhours, we will use a JupyterHub set-up with geospatial packages and data. These sessions will get you more familiar with JupyterHubs, Jupyter notebooks, and Python/R for geospatial analysis.\nAdd event to your calendar Use this form to sign-up for access to the JupyterHub and to be alerted for future hackdays: SIGN-UP FORM\n\nMarch 8th. Using MODIS/Terra Snow Cover Daily L3 Global 0.05Deg from tutorial Appendix 1\nMarch 15th. TBD. Maybe let’s do a Coastwatch tutorial or GIS (via the arcgic Python API).\nMarch 22nd. Species distribution modeling. Let’s fit a SDM using ocean climate variables (R).\nMarch 29th. Machine learning with tensorflow! It is not that hard. Let’s do some machine-learning with SST rasters (Python).\n\nDon’t know Python? Python is not as commonly use in NMFS. There are lots of free tutorials and classes. Feel free to use the JupyterHub to run through Python course material.\n\n\nDecember 19, 2023\nWorkshop Google Doc (NOAA internal)\n\n8-10am PT Welcome and 2 geospatial tutorials in R and Python\n\nLecture on earth data in the cloud by Michele Thornton (NASA Openscapes) Video\nNASA Earth Data Access in Python\nNASA Earth data in R\nIntro to geospatial data in cloud by Carl Boettiger\n\n10-11am PT Explore data and come up with a project\n11-12pm PT Break and lunch\n12-12:30pm PT Pitch a project!\n12:30-2:30pm PT Hack and co-work on the project\n2:30-3pm PT Report out!"
  },
  {
    "objectID": "index.html#stop-your-jupyter-hub-at-the-end-of-the-day",
    "href": "index.html#stop-your-jupyter-hub-at-the-end-of-the-day",
    "title": "Using Earth Data in R and Python",
    "section": "Stop your Jupyter Hub at the end of the day",
    "text": "Stop your Jupyter Hub at the end of the day\nIf you are in Jupyter lab in the browser:\n\nFile &gt; Hub Control Panel &gt; Stop my server\n\nIf you are in RStudio and you still have the Jupyter lab tab open in your browser:\n\nGo to the Jupyter lab tab\nFile &gt; Hub Control Panel &gt; Stop my server\n\nIf you are in RStudio and you do not have the Jupyter lab tab open in your browser because you closed that tab:\n\nGo to the url https://&lt;jupyterhub url&gt;/user/&lt;your username in the hub&gt;/lab/ That will open the Jupyter lab tab\nFile &gt; Hub Control Panel &gt; Stop my server\nClose out your JupyterHub instance if you are finished for the day, following these instructions."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "The content and tutorials today will be a mix of a workshop by the NASA Openscapes mentors at AGU Dec 10, 2023: 2023 Cloud AGU Workshop and content developed by Carl Boettiger for NASA TOPS-T Cloud Native Geospatial in R & Python."
  },
  {
    "objectID": "about.html#acknowledgements",
    "href": "about.html#acknowledgements",
    "title": "About",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nToday’s workshop content has been developed as a cross-DAAC collaboration by the NASA-Openscapes Team. Learn more at nasa-openscapes.github.io. R content developed by Carl Boettiger (UC Berkeley) and Boettiger lab along with the NASA and NMFS Openscapes mentors."
  },
  {
    "objectID": "coc.html",
    "href": "coc.html",
    "title": "Code of Conduct",
    "section": "",
    "text": "We are dedicated to providing a harassment-free learning experience for everyone regardless of gender, gender identity and expression, sexual orientation, disability, physical appearance, body size, race, age or religion. We do not tolerate harassment of participants in any form. Sexual language and imagery is not appropriate either in-person or virtual form, including the Discussion boards and Slack workspace. Participants (including event volunteers and organizers) violating these rules may be sanctioned or expelled from the event at the discretion of the organizers."
  },
  {
    "objectID": "coc.html#definition-of-harassment",
    "href": "coc.html#definition-of-harassment",
    "title": "Code of Conduct",
    "section": "Definition of Harassment",
    "text": "Definition of Harassment\nHarassment includes, but is not limited to:\n\nVerbal comments that reinforce social structures of domination related to gender, gender identity and expression, sexual orientation, disability, physical appearance, body size, race, age, religion.\nSexual images in public spaces\nDeliberate intimidation, stalking, or following\nHarassing photography or recording\nSustained disruption of talks or other events\nInappropriate physical contact\nUnwelcome sexual attention\nAdvocating for, or encouraging, any of the above behavior"
  },
  {
    "objectID": "coc.html#expectations",
    "href": "coc.html#expectations",
    "title": "Code of Conduct",
    "section": "Expectations",
    "text": "Expectations\nParticipants asked to stop any harassing behavior are expected to comply immediately. If a participant engages in harassing behavior, the organizers retain the right to take any actions to keep the event a welcoming environment for all participants. This includes warning the offender or expulsion from the event.\nThe organizers may take action to redress anything designed to, or with the clear impact of, disrupting the event or making the environment hostile for any participants. We expect participants to follow these rules at all the event venues and event-related social activities."
  },
  {
    "objectID": "coc.html#reporting-a-violation",
    "href": "coc.html#reporting-a-violation",
    "title": "Code of Conduct",
    "section": "Reporting a violation",
    "text": "Reporting a violation\nHarassment and other code of conduct violations reduce the value of the event for everyone. If someone makes you or anyone else feel unsafe or unwelcome, please report it as soon as possible.\nIf you feel comfortable contacting someone associated with our event, you may speak with one of the event organizers in person or contact an organizer on a private Slack channel."
  },
  {
    "objectID": "itutorials/Earthdata_Search_Discovery_earthaccess.html#summary",
    "href": "itutorials/Earthdata_Search_Discovery_earthaccess.html#summary",
    "title": "Data discovery with earthaccess",
    "section": "Summary",
    "text": "Summary\nIn this example we will use the earthaccess library to search for data collections from NASA Earthdata. earthaccess is a Python library that simplifies data discovery and access to NASA Earth science data by providing an abstraction layer for NASA’s Common Metadata Repository (CMR) API Search API. The library makes searching for data more approachable by using a simpler notation instead of low level HTTP queries. earthaccess takes the trouble out of Earthdata Login authentication, makes search easier, and provides a stream-line way to download or stream search results into an xarray object.\nFor more on earthaccess visit the earthaccess GitHub page and/or the earthaccess documentation site. Be aware that earthaccess is under active development."
  },
  {
    "objectID": "itutorials/Earthdata_Search_Discovery_earthaccess.html#prerequisites",
    "href": "itutorials/Earthdata_Search_Discovery_earthaccess.html#prerequisites",
    "title": "Data discovery with earthaccess",
    "section": "Prerequisites",
    "text": "Prerequisites\nAn Earthdata Login account is required to access data from NASA Earthdata. Please visit https://urs.earthdata.nasa.gov to register and manage your Earthdata Login account. This account is free to create and only takes a moment to set up."
  },
  {
    "objectID": "itutorials/Earthdata_Search_Discovery_earthaccess.html#learning-objectives",
    "href": "itutorials/Earthdata_Search_Discovery_earthaccess.html#learning-objectives",
    "title": "Data discovery with earthaccess",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nHow to authenticate with earthaccess\nHow to use earthaccess to search for data using spatial and temporal filters\nHow to explore and work with search results"
  },
  {
    "objectID": "itutorials/Earthdata_Search_Discovery_earthaccess.html#get-started",
    "href": "itutorials/Earthdata_Search_Discovery_earthaccess.html#get-started",
    "title": "Data discovery with earthaccess",
    "section": "Get Started",
    "text": "Get Started\n\nImport Required Packages\n\nimport earthaccess \nfrom pprint import pprint\nimport xarray as xr\nimport geopandas as gpd\n\n\nimport os\nos.environ[\"HOME\"] = \"/home/jovyan\"\n\n\nauth = earthaccess.login()\n# are we authenticated?\nif not auth.authenticated:\n    # ask for credentials and persist them in a .netrc file\n    auth.login(strategy=\"interactive\", persist=True)\n\nWe are already authenticated with NASA EDL\n\n\n\n\nSearch for data\nThere are multiple keywords we can use to discovery data from collections. The table below contains the short_name, concept_id, and doi for some collections we are interested in for other exercises. Each of these can be used to search for data or information related to the collection we are interested in.\n\n\n\nShortname\nCollection Concept ID\nDOI\n\n\n\n\nGPM_3IMERGDF\nC2723754864-GES_DISC\n10.5067/GPM/IMERGDF/DAY/07\n\n\nMOD10C1\nC1646609808-NSIDC_ECS\n10.5067/MODIS/MOD10C1.061\n\n\nSPL4SMGP\nC2531308461-NSIDC_ECS\n10.5067/EVKPQZ4AFC4D\n\n\nSPL4SMAU\nC2537927247-NSIDC_ECS\n10.5067/LWJ6TF5SZRG3\n\n\n\nBut wait…You may be asking “how can we find the shortname, concept_id, and doi for collections not in the table above?”. Let’s take a quick detour.\nhttps://search.earthdata.nasa.gov/search?q=GPM_3IMERGDF\n\nSearch by collection\n\n#collection_id = 'C2723754864-GES_DISC'\ncollection_id = 'C1598621096-GES_DISC'\n\n\nresults = earthaccess.search_data(\n    concept_id = collection_id,\n    cloud_hosted = True,\n    count = 10    # Restricting to 10 records returned\n)\n\nGranules found: 7792\n\n\nIn this example we used the concept_id parameter to search from our desired collection. However, there are multiple ways to specify the collection(s) we are interested in. Alternative parameters include:\n\ndoi - request collection by digital object identifier (e.g., doi = ‘10.5067/GPM/IMERGDF/DAY/07’)\n\nshort_name - request collection by CMR shortname (e.g., short_name = ‘GPM_3IMERGDF’)\n\nNOTE: Each Earthdata collect has a unique concept_id and doi. This is not the case with short_name. A shortname can be associated with multiple versions of a collection. If multiple versions of a collection are publicaly available, using the short_name parameter with return all versions available. It is advised to use the version parameter in conjunction with the short_name parameter with searching.\nWe can refine our search by passing more parameters that describe the spatiotemporal domain of our use case. Here, we use the temporal parameter to request a date range and the bounding_box parameter to request granules that intersect with a bounding box.\nFor our bounding box, we are going to read in a GeoJSON file containing a single feature and extract the coordinate pairs for the southeast corner and the northwest corner (or lowerleft and upperright corners) of the bounding box around the feature.\n\ninGeojson = gpd.read_file('../../NOAAHackDay-Dec-2023/data/sf_to_sierranvmt.geojson')\n\n\nxmin, ymin, xmax, ymax = inGeojson.total_bounds\n\nWe will assign our start date and end date to a variable named date_range and we’ll assign the southeast and the northwest corner coordinates to a variable named bbox to be passed to our earthaccess search request.\n\n#date_range = (\"2022-11-19\", \"2023-04-06\")\ndate_range = (\"2019-11-19\", \"2019-12-06\")\nbbox = (xmin, ymin, xmax, ymax)\n\n\nresults = earthaccess.search_data(\n    concept_id = collection_id,\n    cloud_hosted = True,\n    temporal = date_range,\n    bounding_box = bbox,\n)\n\nGranules found: 18\n\n\n\nThe short_name and concept_id search parameters can be used to request one or multiple collections per request, but the doi parameter can only request a single collection.\n&gt; concept_ids = [‘C2723754864-GES_DISC’, ‘C1646609808-NSIDC_ECS’]\n\nUse the cloud_hosted search parameter only to search for data assets available from NASA’s Earthdata Cloud.\nThere are even more search parameters that can be passed to help refine our search, however those parameters do have to be populated in the CMR record to be leveraged. A non exhaustive list of examples are below:\n\nday_night_flag = 'day'\n\ncloud_cover = (0, 10)\n\n\n\n# col_ids = ['C2723754864-GES_DISC', 'C1646609808-NSIDC_ECS', 'C2531308461-NSIDC_ECS', 'C2537927247-NSIDC_ECS']    # Specify a list of collections to pass to the search\n\n# results = earthaccess.search_data(\n#     concept_id = col_ids,\n#     #cloud_hosted = True,\n#     temporal = date_range,\n#     bounding_box = bbox,\n# )\n\n\n\n\nWorking with earthaccess returns\nearthaccess provides several convenience methods to help streamline processes that historically have be painful when done using traditional methods. Following the search for data, you’ll likely take one of two pathways with those results. You may choose to download the assets that have been returned to you or you may choose to continue working with the search results within the Python environment.\n\nDownload earthaccess results\nIn some cases you may want to download your assets. earthaccess makes downloading the data from the search results very easy using the earthaccess.download() function.\n\ndownloaded_files = earthaccess.download(\n    results[0:9],\n    local_path='../../NOAAHackDay-Dec-2023/data',\n)\n\n Getting 9 granules, approx download size: 0.27 GB\n\n\n\n\n\n\n\n\n\n\n\nearthaccess did a lot of heavy lifting for us. It identified the downloadable links, passed our Earthdata Login credentials, and save off the file with the proper name. Amazing right!?\nWe’re going to remove those files to keep our space clean.\n\n!rm ../../NOAAHackDay-Dec-2023/data/*.nc4\n\n\n\nExplore earthaccess search response\n\nprint(f'The results variable is a {type(results)} of {type(results[0])}')\n\nThe results variable is a &lt;class 'list'&gt; of &lt;class 'earthaccess.results.DataGranule'&gt;\n\n\n\nlen(results)\n\n18\n\n\nWe can explore the first item (earthaccess.results.DataGranule) in our list.\n\nitem = results[0]\ntype(item)\n\nearthaccess.results.DataGranule\n\n\nEach item contains three keys that can be used to explore the item\n\nitem.keys()\n\ndict_keys(['meta', 'umm', 'size'])\n\n\n\nitem['umm']\n\n{'RelatedUrls': [{'URL': 'https://data.gesdisc.earthdata.nasa.gov/data/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191119-S000000-E235959.V06.nc4', 'Type': 'GET DATA', 'Description': 'Download 3B-DAY.MS.MRG.3IMERG.20191119-S000000-E235959.V06.nc4'}, {'URL': 's3://gesdisc-cumulus-prod-protected/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191119-S000000-E235959.V06.nc4', 'Type': 'GET DATA VIA DIRECT ACCESS', 'Description': 'This link provides direct download access via S3 to the granule'}, {'URL': 'https://gpm1.gesdisc.eosdis.nasa.gov/opendap/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191119-S000000-E235959.V06.nc4', 'Type': 'USE SERVICE API', 'Subtype': 'OPENDAP DATA', 'Description': 'The OPENDAP location for the granule.', 'MimeType': 'application/x-netcdf-4'}, {'URL': 'https://data.gesdisc.earthdata.nasa.gov/s3credentials', 'Type': 'VIEW RELATED INFORMATION', 'Description': 'api endpoint to retrieve temporary credentials valid for same-region direct s3 access'}], 'SpatialExtent': {'HorizontalSpatialDomain': {'Geometry': {'BoundingRectangles': [{'WestBoundingCoordinate': -180.0, 'EastBoundingCoordinate': 180.0, 'NorthBoundingCoordinate': 90.0, 'SouthBoundingCoordinate': -90.0}]}}}, 'ProviderDates': [{'Date': '2020-02-27T16:10:05.000Z', 'Type': 'Insert'}, {'Date': '2020-02-27T16:10:05.000Z', 'Type': 'Update'}], 'CollectionReference': {'ShortName': 'GPM_3IMERGDF', 'Version': '06'}, 'DataGranule': {'DayNightFlag': 'Unspecified', 'Identifiers': [{'Identifier': '3B-DAY.MS.MRG.3IMERG.20191119-S000000-E235959.V06.nc4', 'IdentifierType': 'ProducerGranuleId'}], 'ProductionDateTime': '2020-02-27T16:10:05.000Z', 'ArchiveAndDistributionInformation': [{'Name': 'Not provided', 'Size': 29.92357635498047, 'SizeUnit': 'MB'}]}, 'TemporalExtent': {'RangeDateTime': {'BeginningDateTime': '2019-11-19T00:00:00.000Z', 'EndingDateTime': '2019-11-19T23:59:59.999Z'}}, 'GranuleUR': 'GPM_3IMERGDF.06:3B-DAY.MS.MRG.3IMERG.20191119-S000000-E235959.V06.nc4', 'MetadataSpecification': {'URL': 'https://cdn.earthdata.nasa.gov/umm/granule/v1.6.5', 'Name': 'UMM-G', 'Version': '1.6.5'}}\n\n\n\n\nGet data URLs / S3 URIs\nGet links to data. The data_links() method is used to return the URL(s)/data link(s) for the item. By default the method returns the HTTPS URL to download or access the item.\n\nitem.data_links()\n\n['https://data.gesdisc.earthdata.nasa.gov/data/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191119-S000000-E235959.V06.nc4']\n\n\nThe data_links() method can also be used to get the s3 URI when we want to perform direct s3 access of the data in the cloud. To get the s3 URI, pass access = 'direct' to the method.\n\nitem.data_links(access='direct')\n\n['s3://gesdisc-cumulus-prod-protected/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191119-S000000-E235959.V06.nc4']\n\n\nIf we want to extract all of the data links from our search results and add or save them to a list, we can.\n\ndata_link_list = []\n\nfor granule in results:\n    for asset in granule.data_links(access='direct'):\n        data_link_list.append(asset)\n        \n\n\ndata_link_list[0:9]\n\n['s3://gesdisc-cumulus-prod-protected/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191119-S000000-E235959.V06.nc4',\n 's3://gesdisc-cumulus-prod-protected/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191120-S000000-E235959.V06.nc4',\n 's3://gesdisc-cumulus-prod-protected/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191121-S000000-E235959.V06.nc4',\n 's3://gesdisc-cumulus-prod-protected/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191122-S000000-E235959.V06.nc4',\n 's3://gesdisc-cumulus-prod-protected/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191123-S000000-E235959.V06.nc4',\n 's3://gesdisc-cumulus-prod-protected/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191124-S000000-E235959.V06.nc4',\n 's3://gesdisc-cumulus-prod-protected/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191125-S000000-E235959.V06.nc4',\n 's3://gesdisc-cumulus-prod-protected/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191126-S000000-E235959.V06.nc4',\n 's3://gesdisc-cumulus-prod-protected/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191127-S000000-E235959.V06.nc4']\n\n\nWe can pass or read these lists of data links into libraries like xarray, rioxarray, or gdal, but earthaccess has a built-in module for easily reading these data links in.\n\n\nOpen results in xarray\nWe use earthaccess’s open() method to make a connection to and open the files from our search result.\n\nfileset = earthaccess.open(results)\n\n Opening 18 granules, approx size: 0.53 GB\n\n\n\n\n\n\n\n\n\n\n\nThen we pass the fileset object to xarray.\n\nds = xr.open_mfdataset(fileset, chunks = {})\n\nSome really cool things just happened here! Not only were we able to seamlessly stream our earthaccess search results into a xarray dataset using the open_mfdataset() (multi-file) method, but earthaccess whether we were working from within AWS us-west-2 and could use direct S3 access or if not, would use https. We didn’t have to create a session or a filesystem to authenticate and connect to the data. earthaccess did this for us using the auth object we created at the beginning of this tutorial.\nLet’s take a quick lock at our xarray dataset\n\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:                    (time: 18, lon: 3600, lat: 1800, nv: 2)\nCoordinates:\n  * lon                        (lon) float32 -179.9 -179.8 ... 179.9 179.9\n  * lat                        (lat) float32 -89.95 -89.85 ... 89.85 89.95\n  * time                       (time) object 2019-11-19 00:00:00 ... 2019-12-...\nDimensions without coordinates: nv\nData variables:\n    precipitationCal           (time, lon, lat) float32 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    precipitationCal_cnt       (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    precipitationCal_cnt_cond  (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    HQprecipitation            (time, lon, lat) float32 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    HQprecipitation_cnt        (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    HQprecipitation_cnt_cond   (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    randomError                (time, lon, lat) float32 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    randomError_cnt            (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    time_bnds                  (time, nv) object dask.array&lt;chunksize=(1, 2), meta=np.ndarray&gt;\nAttributes:\n    BeginDate:       2019-11-19\n    BeginTime:       00:00:00.000Z\n    EndDate:         2019-11-19\n    EndTime:         23:59:59.999Z\n    FileHeader:      StartGranuleDateTime=2019-11-19T00:00:00.000Z;\\nStopGran...\n    InputPointer:    3B-HHR.MS.MRG.3IMERG.20191119-S000000-E002959.0000.V06B....\n    title:           GPM IMERG Final Precipitation L3 1 day 0.1 degree x 0.1 ...\n    DOI:             10.5067/GPM/IMERGDF/DAY/06\n    ProductionTime:  2020-02-27T16:09:48.308Zxarray.DatasetDimensions:time: 18lon: 3600lat: 1800nv: 2Coordinates: (3)lon(lon)float32-179.9 -179.8 ... 179.9 179.9units :degrees_eastlong_name :Longitudearray([-179.95   , -179.84999, -179.75   , ...,  179.75002,  179.85002,\n        179.95   ], dtype=float32)lat(lat)float32-89.95 -89.85 ... 89.85 89.95units :degrees_northlong_name :Latitudearray([-89.95    , -89.85    , -89.75    , ...,  89.75    ,  89.850006,\n        89.95001 ], dtype=float32)time(time)object2019-11-19 00:00:00 ... 2019-12-...standard_name :timebounds :time_bndsarray([cftime.DatetimeJulian(2019, 11, 19, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 20, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 21, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 22, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 23, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 24, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 25, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 26, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 27, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 28, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 29, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 30, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 12, 1, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 12, 2, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 12, 3, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 12, 4, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 12, 5, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 12, 6, 0, 0, 0, 0, has_year_zero=False)],\n      dtype=object)Data variables: (9)precipitationCal(time, lon, lat)float32dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;units :mmlong_name :Daily accumulated precipitation (combined microwave-IR) estimate\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n444.95 MiB\n24.72 MiB\n\n\nShape\n(18, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n18 chunks in 37 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\nprecipitationCal_cnt\n\n\n(time, lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\ncount\n\nlong_name :\n\nCount of all valid half-hourly precipitationCal retrievals for the day\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n111.24 MiB\n6.18 MiB\n\n\nShape\n(18, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n18 chunks in 37 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n\n\n\n\n\nprecipitationCal_cnt_cond\n\n\n(time, lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\ncount\n\nlong_name :\n\nCount of valid half-hourly precipitationCal retrievals for the day where precipitation is greater than 0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n111.24 MiB\n6.18 MiB\n\n\nShape\n(18, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n18 chunks in 37 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n\n\n\n\n\nHQprecipitation\n\n\n(time, lon, lat)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\nmm\n\nlong_name :\n\nDaily accumulated High Quality precipitation from all available MW sources\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n444.95 MiB\n24.72 MiB\n\n\nShape\n(18, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n18 chunks in 37 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\n\nHQprecipitation_cnt\n\n\n(time, lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\ncount\n\nlong_name :\n\nCount of all valid half-hourly HQprecipitation retrievals for the day\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n111.24 MiB\n6.18 MiB\n\n\nShape\n(18, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n18 chunks in 37 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n\n\n\n\n\nHQprecipitation_cnt_cond\n\n\n(time, lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\ncount\n\nlong_name :\n\nCount of valid half-hourly HQprecipitation retrievals for the day where precipitation is greater than 0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n111.24 MiB\n6.18 MiB\n\n\nShape\n(18, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n18 chunks in 37 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n\n\n\n\n\nrandomError\n\n\n(time, lon, lat)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\nmm\n\nlong_name :\n\nDaily total error of precipitation estimate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n444.95 MiB\n24.72 MiB\n\n\nShape\n(18, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n18 chunks in 37 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\n\nrandomError_cnt\n\n\n(time, lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\ncount\n\nlong_name :\n\nCount of valid half-hourly randomError retrievals for the day\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n111.24 MiB\n6.18 MiB\n\n\nShape\n(18, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n18 chunks in 37 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n\n\n\n\n\ntime_bnds\n\n\n(time, nv)\n\n\nobject\n\n\ndask.array&lt;chunksize=(1, 2), meta=np.ndarray&gt;\n\n\n\n\ncoordinates :\n\ntime nv\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n288 B\n16 B\n\n\nShape\n(18, 2)\n(1, 2)\n\n\nDask graph\n18 chunks in 37 graph layers\n\n\nData type\nobject numpy.ndarray\n\n\n\n\n\n\n\n\nIndexes: (3)lonPandasIndexPandasIndex(Float64Index([ -179.9499969482422, -179.84999084472656,             -179.75,\n              -179.64999389648438,  -179.5500030517578,  -179.4499969482422,\n              -179.34999084472656,             -179.25, -179.14999389648438,\n               -179.0500030517578,\n              ...\n                179.0500030517578,  179.15000915527344,  179.25001525878906,\n                179.3500213623047,   179.4499969482422,   179.5500030517578,\n               179.65000915527344,  179.75001525878906,   179.8500213623047,\n                179.9499969482422],\n             dtype='float64', name='lon', length=3600))latPandasIndexPandasIndex(Float64Index([-89.94999694824219,  -89.8499984741211,             -89.75,\n              -89.64999389648438, -89.54999542236328, -89.44999694824219,\n               -89.3499984741211,             -89.25, -89.14999389648438,\n              -89.04999542236328,\n              ...\n               89.05000305175781,  89.15000915527344,              89.25,\n               89.35000610351562,  89.45001220703125,  89.55000305175781,\n               89.65000915527344,              89.75,  89.85000610351562,\n               89.95001220703125],\n             dtype='float64', name='lat', length=1800))timePandasIndexPandasIndex(CFTimeIndex([2019-11-19 00:00:00, 2019-11-20 00:00:00, 2019-11-21 00:00:00,\n             2019-11-22 00:00:00, 2019-11-23 00:00:00, 2019-11-24 00:00:00,\n             2019-11-25 00:00:00, 2019-11-26 00:00:00, 2019-11-27 00:00:00,\n             2019-11-28 00:00:00, 2019-11-29 00:00:00, 2019-11-30 00:00:00,\n             2019-12-01 00:00:00, 2019-12-02 00:00:00, 2019-12-03 00:00:00,\n             2019-12-04 00:00:00, 2019-12-05 00:00:00, 2019-12-06 00:00:00],\n            dtype='object', length=18, calendar='julian', freq='D'))Attributes: (9)BeginDate :2019-11-19BeginTime :00:00:00.000ZEndDate :2019-11-19EndTime :23:59:59.999ZFileHeader :StartGranuleDateTime=2019-11-19T00:00:00.000Z;\nStopGranuleDateTime=2019-11-19T23:59:59.999ZInputPointer :3B-HHR.MS.MRG.3IMERG.20191119-S000000-E002959.0000.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S003000-E005959.0030.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S010000-E012959.0060.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S013000-E015959.0090.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S020000-E022959.0120.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S023000-E025959.0150.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S030000-E032959.0180.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S033000-E035959.0210.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S040000-E042959.0240.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S043000-E045959.0270.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S050000-E052959.0300.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S053000-E055959.0330.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S060000-E062959.0360.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S063000-E065959.0390.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S070000-E072959.0420.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S073000-E075959.0450.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S080000-E082959.0480.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S083000-E085959.0510.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S090000-E092959.0540.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S093000-E095959.0570.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S100000-E102959.0600.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S103000-E105959.0630.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S110000-E112959.0660.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S113000-E115959.0690.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S120000-E122959.0720.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S123000-E125959.0750.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S130000-E132959.0780.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S133000-E135959.0810.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S140000-E142959.0840.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S143000-E145959.0870.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S150000-E152959.0900.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S153000-E155959.0930.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S160000-E162959.0960.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S163000-E165959.0990.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S170000-E172959.1020.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S173000-E175959.1050.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S180000-E182959.1080.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S183000-E185959.1110.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S190000-E192959.1140.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S193000-E195959.1170.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S200000-E202959.1200.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S203000-E205959.1230.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S210000-E212959.1260.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S213000-E215959.1290.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S220000-E222959.1320.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S223000-E225959.1350.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S230000-E232959.1380.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S233000-E235959.1410.V06B.HDF5title :GPM IMERG Final Precipitation L3 1 day 0.1 degree x 0.1 degree (GPM_3IMERGDF)DOI :10.5067/GPM/IMERGDF/DAY/06ProductionTime :2020-02-27T16:09:48.308Z"
  },
  {
    "objectID": "itutorials/Earthdata_Search_Discovery_earthaccess.html#resources",
    "href": "itutorials/Earthdata_Search_Discovery_earthaccess.html#resources",
    "title": "Data discovery with earthaccess",
    "section": "Resources",
    "text": "Resources\n\nNASA’s Common Metadata Repository (CMR) API\n\nearthaccess repository\nearthaccess documentation\nEarthdata Search"
  },
  {
    "objectID": "itutorials/Introduction_to_Cloud_Python.html",
    "href": "itutorials/Introduction_to_Cloud_Python.html",
    "title": "Introduction to Geospatial Analyses in R in the Cloud",
    "section": "",
    "text": "This is based on the “Examining Environmental Justice through Open Source, Cloud-Native Tools” notebook from Carl Boettiger. Please follow Carl’s notebook for the background. This tutorial just focuses on the code."
  },
  {
    "objectID": "itutorials/Introduction_to_Cloud_Python.html#data-discovery",
    "href": "itutorials/Introduction_to_Cloud_Python.html#data-discovery",
    "title": "Introduction to Geospatial Analyses in R in the Cloud",
    "section": "Data discovery",
    "text": "Data discovery\nHere we use a STAC Catalog API to recover a list of candidate data. This example searches for images in a lon-lat bounding box from a collection of Cloud-Optimized-GeoTIFF (COG) images taken by Sentinel2 satellite mission. This function will not download any imagery, it merely gives us a list of metadata about available images.\n\nbox = [-122.51, 37.71, -122.36, 37.81]\nitems = (\n  Client.\n  open(\"https://earth-search.aws.element84.com/v1\").\n  search(\n    collections = ['sentinel-2-l2a'],\n    bbox = box,\n    datetime = \"2022-06-01/2022-08-01\",\n    query={\"eo:cloud_cover\": {\"lt\": 20}}).\n  item_collection()\n)\n\nWe pass this list of images to a high-level utilty (gdalcubes) that will do all of the heavy lifting:\n\nsubsetting by date\nsubsetting by bounding box\naggregating by time P1D\nreproject into the desired coordinate system\nresampling to a desired spatial resolution\n\n\ndata = odc.stac.load(\n    items,\n    crs=\"EPSG:4326\",\n    bands=[\"nir08\", \"red\"],\n    resolution=0.0001,\n    bbox=box\n)\n\nCalculate NDVI, a widely used measure of greenness that can be used to determine tree cover.\n\nred = data.red\nnir = data.nir08\n\nndvi = (((nir - red) / (red + nir)).\n        resample(time=\"MS\").\n        median(\"time\", keep_attrs=True).\n        compute()\n)\n\n# mask out bad pixels\nndvi = ndvi.where(ndvi &lt;= 1)\n\nPlot the result. The long rectangle of Golden Gate Park is clearly visible in the North-West.\n\nimport matplotlib as plt\ncmap = plt.colormaps.get_cmap('viridis')  # viridis is the default colormap for imshow\ncmap.set_bad(color='black')\n\nndvi.plot.imshow(row=\"time\", cmap=cmap, add_colorbar=False, size=5)\n\n&lt;xarray.plot.facetgrid.FacetGrid at 0x7f7c98163ac0&gt;\n\n\n\n\n\nAdd the 1937 “red-lining” zones from the Mapping Inequality project. The red-lined zones are spatial vectors.\n\nndvi.rio.to_raster(raster_path=\"ndvi.tif\", driver=\"COG\")\nsf_url = \"/vsicurl/https://dsl.richmond.edu/panorama/redlining/static/citiesData/CASanFrancisco1937/geojson.json\"\nmean_ndvi = zonal_stats(sf_url, \"ndvi.tif\", stats=\"mean\")\n\nNow we can plot\n\nsf = gpd.read_file(sf_url)\nsf[\"ndvi\"] = [x[\"mean\"] for x in mean_ndvi ]\nsf.plot(column=\"ndvi\", legend=True)\n\n&lt;Axes: &gt;\n\n\n\n\n\nCompute the mean current greenness by 1937 zone.\n\nimport geopolars as gpl\nimport polars as pl\n\n(gpl.\n  from_geopandas(sf).\n  group_by(\"grade\").\n  agg(pl.col(\"ndvi\").mean()).\n  sort(\"grade\")\n)\n\n\nshape: (5, 2)\n\n\n\ngrade\nndvi\n\n\nstr\nf64\n\n\n\n\nnull\n0.157821\n\n\n\"A\"\n0.338723\n\n\n\"B\"\n0.247344\n\n\n\"C\"\n0.231182\n\n\n\"D\"\n0.225696"
  },
  {
    "objectID": "qtutorials/Introduction_to_Cloud_R.html",
    "href": "qtutorials/Introduction_to_Cloud_R.html",
    "title": "Introduction to Geospatial Analyses in R in the Cloud",
    "section": "",
    "text": "This is based on the “Examining Environmental Justice through Open Source, Cloud-Native Tools” notebook from Carl Boettiger. Please follow Carl’s notebook for the background. This tutorial just focuses on the code."
  },
  {
    "objectID": "qtutorials/Introduction_to_Cloud_R.html#set-up",
    "href": "qtutorials/Introduction_to_Cloud_R.html#set-up",
    "title": "Introduction to Geospatial Analyses in R in the Cloud",
    "section": "Set up",
    "text": "Set up\nYou will need to install the newest version of tmap. Restart R a few times after installing. You don’t need to update other packages.\n\nremotes::install_github('r-tmap/tmap')\n\n\nlibrary(rstac)\nlibrary(gdalcubes)\nlibrary(stars)\nlibrary(tmap)\nlibrary(dplyr)\ngdalcubes::gdalcubes_options(parallel = TRUE)"
  },
  {
    "objectID": "qtutorials/Introduction_to_Cloud_R.html#data-discovery",
    "href": "qtutorials/Introduction_to_Cloud_R.html#data-discovery",
    "title": "Introduction to Geospatial Analyses in R in the Cloud",
    "section": "Data discovery",
    "text": "Data discovery\nHere we use a STAC Catalog API to recover a list of candidate data. This example searches for images in a lon-lat bounding box from a collection of Cloud-Optimized-GeoTIFF (COG) images taken by Sentinel2 satellite mission. This function will not download any imagery, it merely gives us a list of metadata about available images.\n\nbox &lt;- c(xmin=-122.51, ymin=37.71, xmax=-122.36, ymax=37.81) \nstart_date &lt;- \"2022-06-01\"\nend_date &lt;- \"2022-08-01\"\nitems &lt;-\n  stac(\"https://earth-search.aws.element84.com/v0/\") |&gt;\n  stac_search(collections = \"sentinel-s2-l2a-cogs\",\n              bbox = box,\n              datetime = paste(start_date, end_date, sep=\"/\"),\n              limit = 100) |&gt;\n  ext_query(\"eo:cloud_cover\" &lt; 20) |&gt;\n  post_request()\n\nWe pass this list of images to a high-level utilty (gdalcubes) that will do all of the heavy lifting:\n\nsubsetting by date\nsubsetting by bounding box\naggregating by time P1D\nreproject into the desired coordinate system\nresampling to a desired spatial resolution\nresample from images in overlapping areas to replace pixels masked by clouds\n\n\ncol &lt;- stac_image_collection(items$features, asset_names = c(\"B08\", \"B04\", \"SCL\"))\n\ncube &lt;- cube_view(srs =\"EPSG:4326\",\n                  extent = list(t0 = start_date, t1 = end_date,\n                                left = box[1], right = box[3],\n                                top = box[4], bottom = box[2]),\n                  dx = 0.0001, dy = 0.0001, dt = \"P1D\",\n                  aggregation = \"median\", resampling = \"average\")\n\nmask &lt;- image_mask(\"SCL\", values=c(3, 8, 9)) # mask clouds and cloud shadows\n\ndata &lt;-  raster_cube(col, cube, mask = mask)\n\nCalculate NDVI, a widely used measure of greenness that can be used to determine tree cover. The R example uses lazy evaluation, and can thus perform these calculations while streaming.\n\nndvi &lt;- data |&gt;\n  select_bands(c(\"B04\", \"B08\")) |&gt;\n  apply_pixel(\"(B08-B04)/(B08+B04)\", \"NDVI\") |&gt;\n  reduce_time(c(\"mean(NDVI)\"))\n\nndvi_stars &lt;- st_as_stars(ndvi)\n\nPlot the result. The long rectangle of Golden Gate Park is clearly visible in the North-West.\n\nmako &lt;- tm_scale_continuous(values = viridisLite::mako(30))\nfill &lt;- tm_scale_continuous(values = \"Greens\")\n\ntm_shape(ndvi_stars) + tm_raster(col.scale = mako)"
  },
  {
    "objectID": "qtutorials/setup.html#the-environments",
    "href": "qtutorials/setup.html#the-environments",
    "title": "Setup",
    "section": "The environments",
    "text": "The environments\nPython: https://github.com/NASA-Openscapes/corn/blob/main/ci/environment.yml\nR: rocker/geospatial:4.2"
  },
  {
    "objectID": "qtutorials/setup.html#set-up-specific-for-the-jupyterhub",
    "href": "qtutorials/setup.html#set-up-specific-for-the-jupyterhub",
    "title": "Setup",
    "section": "SET UP specific for the JupyterHub",
    "text": "SET UP specific for the JupyterHub\nThis is important. The Dockerfile for RStudio has a bug such that it does not set the path correctly so that the Python is in the conda notebook environment that is on the JHub. You need to run the code below to set this up. Do this from R on the JHub.\nYou only do this once!\n\nRun this code in the R console:\n\nusethis::edit_r_environ()\n\nWhen the .Renviron file opens paste this into it.\n\nPATH = \"/usr/bin:/srv/conda/envs/notebook/bin:/srv/conda/condabin:/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/sbin:/bin:/usr/local/texlive/bin/linux:/usr/local/texlive/bin/linux:/usr/lib/rstudio-server/bin/quarto/bin:/usr/lib/rstudio-server/bin/postback/postback:/usr/bin:/usr/bin:/usr/bin:\"\n\nRestart R. Session &gt; Restart R\nDouble-check Python environment\n\nsystem(\"conda env list\")\nYou should see this\n# conda environments:\n#\nbase                     /srv/conda\nnotebook              *  /srv/conda/envs/notebook"
  }
]